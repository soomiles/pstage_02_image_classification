{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import Subset\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from dataset import MaskBaseDataset\n",
    "from model import *\n",
    "from loss import create_criterion\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def seed_everything(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- parameters\n",
    "img_root = os.getenv(\"IMG_ROOT\")\n",
    "label_path = os.getenv(\"LABEL_PATH\")\n",
    "\n",
    "val_split = 0.4\n",
    "batch_size = 64\n",
    "num_workers = 32  # todo : fix\n",
    "num_classes = 3\n",
    "\n",
    "num_epochs = 100\n",
    "lr = 1e-4\n",
    "lr_decay_step = 10\n",
    "criterion_name = 'label_smoothing'\n",
    "\n",
    "n_splits = 5\n",
    "\n",
    "train_log_interval = 20\n",
    "name = \"02_vgg\"\n",
    "\n",
    "# -- settings\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "# -- wandb initialize with configuration\n",
    "wandb.init(config={\"batch_size\": batch_size,\n",
    "                   \"lr\"        : lr,\n",
    "                   \"epochs\"    : num_epochs,\n",
    "                   \"backborn\"  : name})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader\n",
    "- index를 사용한 Dataloader 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataloader(dataset, train_idx, valid_idx, batch_size, num_workers):\n",
    "    train_set = torch.utils.data.Subset(dataset,\n",
    "                                        indices=train_idx)\n",
    "    val_set   = torch.utils.data.Subset(dataset,\n",
    "                                        indices=valid_idx)\n",
    "    val_set.dataset.set_phase(\"test\")\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_set,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True,\n",
    "    )\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_set,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True,\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified k-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MaskBaseDataset(img_root, label_path, 'train')\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_splits)\n",
    "\n",
    "best_val_acc = 0\n",
    "best_val_loss = np.inf\n",
    "for i, (train_idx, valid_idx) in enumerate(skf.split(dataset.image_paths, dataset.labels)):\n",
    "    train_loader, val_loader = getDataloader(dataset, train_idx, valid_idx, batch_size, num_workers)\n",
    "\n",
    "    # -- model\n",
    "    if False:\n",
    "        model = AlexNet(num_classes=num_classes).to(device)\n",
    "    else:\n",
    "        model = VGG19(num_classes=num_classes, pretrained=True, freeze=False).to(device)\n",
    "\n",
    "    # -- loss & metric\n",
    "    criterion = create_criterion(criterion_name)\n",
    "    optimizer = Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, weight_decay=5e-4)\n",
    "    scheduler = StepLR(optimizer, lr_decay_step, gamma=0.5)\n",
    "    # metrics = []\n",
    "    # callbacks = []\n",
    "\n",
    "    # -- logging\n",
    "    logger = SummaryWriter(log_dir=f\"results/cv{i}_{name}\")\n",
    "    for epoch in range(num_epochs):\n",
    "        # train loop\n",
    "        model.train()\n",
    "        loss_value = 0\n",
    "        matches = 0\n",
    "        for idx, train_batch in enumerate(train_loader):\n",
    "            inputs, labels = train_batch\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outs = model(inputs)\n",
    "            preds = torch.argmax(outs, dim=-1)\n",
    "            loss = criterion(outs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_value += loss.item()\n",
    "            matches += (preds == labels).sum().item()\n",
    "            if (idx + 1) % train_log_interval == 0:\n",
    "                train_loss = loss_value / train_log_interval\n",
    "                train_acc = matches / batch_size / train_log_interval\n",
    "                current_lr = optimizer.param_groups[0]['lr']\n",
    "                print(\n",
    "                    f\"Epoch[{epoch}/{num_epochs}]({idx + 1}/{len(train_loader)}) || \"\n",
    "                    f\"training loss {train_loss:4.4} || training accuracy {train_acc:4.2%} || lr {current_lr}\"\n",
    "                )\n",
    "                logger.add_scalar(\"Train/loss\", train_loss, epoch * len(train_loader) + idx)\n",
    "                logger.add_scalar(\"Train/accuracy\", train_acc, epoch * len(train_loader) + idx)\n",
    "\n",
    "                loss_value = 0\n",
    "                matches = 0\n",
    "\n",
    "                # logging wandb train phase \n",
    "                wandb.log({\n",
    "                    \"Train loss\": train_loss,\n",
    "                    \"Train acc\" : train_acc\n",
    "                })\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        # val loop\n",
    "        with torch.no_grad():\n",
    "            print(\"Calculating validation results...\")\n",
    "            model.eval()\n",
    "            val_loss_items = []\n",
    "            val_acc_items = []\n",
    "            for val_batch in val_loader:\n",
    "                inputs, labels = val_batch\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outs = model(inputs)\n",
    "                preds = torch.argmax(outs, dim=-1)\n",
    "\n",
    "                loss_item = criterion(outs, labels).item()\n",
    "                acc_item = (labels == preds).sum().item()\n",
    "                val_loss_items.append(loss_item)\n",
    "                val_acc_items.append(acc_item)\n",
    "\n",
    "            val_loss = np.sum(val_loss_items) / len(val_loader)\n",
    "            val_acc = np.sum(val_acc_items) / len(valid_idx)\n",
    "            if val_loss < best_val_loss:\n",
    "                print(\"New best model for val loss! saving the model..\")\n",
    "                torch.save(model.state_dict(), f\"results/{name}/{epoch:03}_loss_{val_loss:4.2}.ckpt\")\n",
    "                best_val_loss = val_loss\n",
    "            if val_acc > best_val_acc:\n",
    "                print(\"New best model for val accuracy! saving the model..\")\n",
    "                torch.save(model.state_dict(), f\"results/{name}/{epoch:03}_accuracy_{val_acc:4.2%}.ckpt\")\n",
    "                best_val_acc = val_acc\n",
    "            print(\n",
    "                f\"[Val] acc : {val_acc:4.2%}, loss: {val_loss:4.2} || \"\n",
    "                f\"best acc : {best_val_acc:4.2%}, best loss: {best_val_loss:4.2}\"\n",
    "            )\n",
    "            logger.add_scalar(\"Val/loss\", val_loss, epoch)\n",
    "            logger.add_scalar(\"Val/accuracy\", val_acc, epoch)\n",
    "            print()\n",
    "\n",
    "            # logging wandb valid phase\n",
    "            wandb.log({\n",
    "                \"Valid loss\": val_loss,\n",
    "                \"Valid acc\" : val_acc\n",
    "            })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kyle",
   "language": "python",
   "name": "kyle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
